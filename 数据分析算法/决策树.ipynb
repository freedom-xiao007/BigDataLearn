{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "***\n",
    "## 决策树的生成\n",
    "&ensp;&ensp;&ensp;&ensp;决策树的生成会经历两个阶段:构造和剪纸\n",
    "\n",
    "### 构造\n",
    "&ensp;&ensp;&ensp;&ensp;构造就是生成一颗完整的决策树.简单来说,构造的过程就是选择什么属性作为节点的过程,在构造过程中会存在三种节点:\n",
    "\n",
    "- 根节点:决策树最开始的节点\n",
    "- 内部节点:决策树中间的节点\n",
    "- 叶节点:决策树最底部的节点\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;在构造的过程中需要解决三个重要的问题:\n",
    "\n",
    "- 1.选择哪个属性作为根节点\n",
    "- 2.选择哪些属性作为子节点\n",
    "- 3.什么时候停止并得到目标节点状态,即叶节点\n",
    "\n",
    "### 剪枝\n",
    "&ensp;&ensp;&ensp;&ensp;剪枝就是给决策树瘦身,使不需要太多的判断的同时能得到不错的结果,防止过拟合现象的发生.剪枝又分为预剪枝和后剪枝.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;预剪枝是在决策树构造时就进行剪枝.方法是在构造的过程中对节点进行评估,如果对某个节点进行划分,在验证集中不能带来准确性的提升,那么对这个节点进行划分就没有意义,这时就会把当前节点当做叶节点,不对其进行划分.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;后剪枝就是在生成决策树之后再进行剪枝,通常会从决策树的叶节点开始,逐层向上对每个节点进行评估.如果减掉这个节点子树,与保留该节点子树在分类上准确性差别不大或有所提升,那么就可以把该节点子树进行剪枝.方法是:用这个节点子树的叶子节点来替代该节点,类标记为这个节点子树中最频繁的那个类.\n",
    "\n",
    "### 节点选择\n",
    "&ensp;&ensp;&ensp;&ensp;给出一个打篮球的数据集如下:\n",
    "\n",
    "|天气|温度|湿度|刮风|是否打篮球|\n",
    "|----|:--:|:--:|:--:|--------|\n",
    "|晴|高|中|否|否|\n",
    "|晴|高|中|是|否|\n",
    "|阴|高|高|否|是|\n",
    "|小雨|高|高|否|是|\n",
    "|小雨|低|高|否|否|\n",
    "|晴天|中|中|是|是|\n",
    "|阴天|中|高|是|否|\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;在这个探讨将那个属性(天气,温度,湿度,刮风)作为根节点的关键问题,这里是根据纯度和信息熵进行选择的,在纯度和信息熵之间有关联关系:纯度越低,信息熵越大;纯度越高,信息熵越小.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;关于的纯度和信息熵的具体信息和数学公式在极客时间-数据分析实战45讲-17讲里面有,这里不叙述了,数学公式之类太繁琐,可能会说不清楚,极客时间里面讲的还行,需要的可以去看看.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;在构造决策树时会基于纯度来构建,而经典的\"不纯度\"的指标有三种,分别是信息增益(ID3算法),信息增益率(C4.5算法)以及基尼指数(Cart算法),这篇文件介绍ID3算法.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;ID3算法计算的是信息增益,信息增益指的是划分可以带来纯度的提高,信息熵的下降.它的计算公式是父亲节点的信息熵减去所有子节点的信息熵.在计算的过程中,会计算每个子节点的归一化信息熵,即按照每个子节点在父节点中出现的概率,来计算这些子节点的信息熵.\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;在构造的过程中需要计算两个东西:信息熵,信息增益.下面以打篮球的数据集为例如何计算:\n",
    "\n",
    "#### 信息熵\n",
    "##### 根节点信息熵\n",
    "&ensp;&ensp;&ensp;&ensp;信息熵的计算公式如下:\n",
    "\n",
    "$$Ent(D) = - \\sum p_k \\log_2 p_k$$\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;其中的累加次数为结果数量,这个就是2(去打篮球和不去打篮球).$p_k$表示的是每个累加情况的概率,在上面的数据集中有7条数据,3个打篮球,4个不打篮球,那么不去打篮球的$p_k$为$\\frac{4}{7}$,去打篮球为 $\\frac{3}{7}$.则在根节点为空的情况下,根节点信息熵为:\n",
    "\n",
    "$$Ent(D) = - \\sum p_k \\log_2 p_k = - (\\frac{4}{7} \\log_2 \\frac{4}{7} + \\frac{3}{7} \\log_2 \\frac{3}{7}) = 0.985$$\n",
    "\n",
    "##### 归一化信息熵\n",
    "&ensp;&ensp;&ensp;&ensp;如果将天气作为属性划分,分别会有三个叶节点D1(晴天),D2(阴天),D3(小雨),用+代表去打篮球,-代表不去打篮球,+-符号前面是数据序号,那D1,D2,D3可以表示如下:\n",
    "\n",
    "- D1(天气=晴天)={1-,2-,6+}\n",
    "- D2(天气=阴天)={3+,7-}\n",
    "- D3(天气=小雨)={4+,5-}\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;三个叶节点的信息熵为:\n",
    "\n",
    "$$Ent(D1) = - (\\frac{1}{3} log_2 \\frac{1}{3} + \\frac{2}{3} log_2 \\frac{2}{3}) = 0.918$$\n",
    "$$Ent(D2) = - (\\frac{1}{2} log_2 \\frac{1}{2} + \\frac{1}{2} log_2 \\frac{1}{2}) = 1.0$$\n",
    "$$Ent(D3) = - (\\frac{1}{2} log_2 \\frac{1}{2} + \\frac{1}{2} log_2 \\frac{1}{2}) = 1.0$$\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;D为天气,D1有3个记录,D2有2个记录,D3有2个记录,一个7条记录.D1在D中的概率为3/7,D2在D中的概率为2/7,D3在D中的概率为2/7.那么作为子节点的归一化信息熵为:$3/7*0.918+2/7*1.0+2/7*1.0=0.965$\n",
    "\n",
    "#### 信息增益\n",
    "&ensp;&ensp;&ensp;&ensp;在上面的信息熵的结果上可以得到天气作为属性节点的信息增益为根节点信息熵-归一化信息熵:$Gain(D,天气)=0.985-0.965=0.020$\n",
    "\n",
    "#### 根据信息熵和信息增益选择节点\n",
    "&ensp;&ensp;&ensp;&ensp;通过上面的例子,可以得到下面的节点的信息增益:\n",
    "\n",
    "- Gain(D,天气)=0.020\n",
    "- Gain(D,温度)=0.128\n",
    "- Gain(D,湿度)=0.020\n",
    "- Gain(D,刮风)=0.020\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;可以看出这里的温度的信息增益最大,所有温度作为整个决策树的根节点.后面根据温度的高中低会生成三个中间节点,而这三个中间节点的选择算法同根节点,如果只有一种结果那这个节点就是叶节点.这样就生成了一颗决策树.\n",
    "\n",
    "## ID3伪算法\n",
    "```python\n",
    "// 提前计算好天气,温度,湿度,刮风的归一化信息熵\n",
    "NWeather = 天气归一化信息熵\n",
    "NTemperature = 温度归一化信息熵\n",
    "NHumidity = 湿度归一化信息熵\n",
    "NWindy = 刮风归一化信息熵\n",
    "\n",
    "// 初始化,选择决策树根节点\n",
    "D = 没有选择根节点的根节点信息熵\n",
    "root = Max(D-NWeather, D-Ntemperature, D-Nhumidity, D-NWindy)\n",
    "fillTree(root)\n",
    "\n",
    "// 遍历当前节点的所有节点进行填充,子节点结果只有一种的就直接赋予结果,多种结果的选择节点后再填充该子节点\n",
    "func fillTree(tree):\n",
    "    children = tree.所有子节点\n",
    "    for child in children:\n",
    "        if 子节点的结果只有一种(如上表中的温度=低就一种结果):\n",
    "            tree.child = 结果(不打篮球)\n",
    "        else:\n",
    "            D(child) = 当前节点的信息熵\n",
    "            tree.child = Max(D(child)-与其不同的归一化信息熵)\n",
    "            fillTree(tree.child)\n",
    "```\n",
    "\n",
    "## ID3算法实现(Python3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9182958340544896 1.0 1.0 0.9649839288804954\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "D1(天气=晴天)={1-,2-,6+}\n",
    "D2(天气=阴天)={3+,7-}\n",
    "D3(天气=小雨)={4+,5-}\n",
    "\"\"\"\n",
    "D1 = -(1/3 * math.log(1/3, 2) + 2/3 * math.log(2/3, 2))\n",
    "D2 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "D3 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "DWeather = 3/7 * D1 + 2/7 * D2 + 2/7 * D3\n",
    "print(D1, D2, D3, DWeather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 -0.0 1.0 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "D1(温度=高)={1-,2-,3+,4+}\n",
    "D2(温度=低)={5-}\n",
    "D3(温度=中)={6+,7-}\n",
    "\"\"\"\n",
    "D4 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "D5 = -(1/1 * math.log(1/1, 2))\n",
    "D6 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "DTemperature = 4/7 * D4 + 1/7 * D5 + 2/7 * D6\n",
    "print(D4, D5, D6, DTemperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9182958340544896 0.9649839288804954\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "D1(湿度=高)={3+,4+,5-,7-}\n",
    "D2(温度=中)={1-,2-,6+}\n",
    "\"\"\"\n",
    "D7 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "D8 = -(2/3 * math.log(2/3, 2) + 1/3 * math.log(1/3, 2))\n",
    "NHumidity = 4/7 * D7 + 3/7 * D8\n",
    "print(D7, D8, NHumidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9182958340544896 0.9649839288804954\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "D1(刮风=否)={1-,3+,4+,5-}\n",
    "D2(刮风=是)={2-,6+,7-}\n",
    "\"\"\"\n",
    "D9 = -(1/2 * math.log(1/2, 2) + 1/2 * math.log(1/2, 2))\n",
    "D10 = -(2/3 * math.log(2/3, 2) + 1/3 * math.log(1/3, 2))\n",
    "NWindy = 4/7 * D9 + 3/7 * D10\n",
    "print(D9, D10, NWindy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852281360342516\n",
      "0.02024420715375619 0.12808527889139454 0.02024420715375619 0.02024420715375619\n",
      "0.12808527889139454\n"
     ]
    }
   ],
   "source": [
    "DRoot = -(4/7 * math.log(4/7, 2) + 3/7 * math.log(3/7, 2))\n",
    "print(DRoot)\n",
    "weatherNode = DRoot - DWeather\n",
    "temperature = DRoot - DTemperature\n",
    "humidity = DRoot - NHumidity\n",
    "windy = DRoot - NWindy\n",
    "print(weatherNode, temperature, humidity, windy)\n",
    "print(max(weatherNode, temperature, humidity, windy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# @Time    : 2019/6/28 16:25\n",
    "# @Author  : LiuWei\n",
    "# @Site    : \n",
    "# @File    : ID3.py\n",
    "# @Software: PyCharm\n",
    "# -*- coding: utf-8 -*-\n",
    "from copy import copy\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def calculateInfoEntropy(trainData, attributeIndex):\n",
    "    \"\"\"\n",
    "\n",
    "    :param trainData:\n",
    "    :param attributeIndex:\n",
    "    :return:\n",
    "    {\n",
    "        status: {\n",
    "            count: value,\n",
    "            value: value,\n",
    "        },\n",
    "        ......\n",
    "    }\n",
    "    \"\"\"\n",
    "    statusStatistics = {}\n",
    "    for item in trainData:\n",
    "        if item[attributeIndex] not in statusStatistics:\n",
    "            statusStatistics[item[attributeIndex]] = {}\n",
    "        if trainData[item] not in statusStatistics[item[attributeIndex]]:\n",
    "            statusStatistics[item[attributeIndex]][trainData[item]] = 1\n",
    "        else:\n",
    "            statusStatistics[item[attributeIndex]][trainData[item]] = statusStatistics[item[attributeIndex]][trainData[item]] + 1\n",
    "\n",
    "    infoEntropyMap = {}\n",
    "    for status in statusStatistics:\n",
    "        amount = 0\n",
    "        for result in statusStatistics[status]:\n",
    "            amount = amount + statusStatistics[status][result]\n",
    "\n",
    "        infoEntropy = 0.0\n",
    "        for result in statusStatistics[status]:\n",
    "            probability = statusStatistics[status][result] / amount\n",
    "            infoEntropy = infoEntropy + (probability * math.log(probability, 2))\n",
    "\n",
    "        infoEntropyMap[status] = {}\n",
    "        infoEntropyMap[status][\"count\"] = amount\n",
    "        infoEntropyMap[status][\"value\"] = infoEntropy * -1\n",
    "    return infoEntropyMap\n",
    "\n",
    "\n",
    "def getInfoEntropy(trainData, properties, propertiesIndex):\n",
    "    \"\"\"\n",
    "\n",
    "    :param trainData:\n",
    "    :param properties:\n",
    "    :param propertiesIndex:\n",
    "    :return:\n",
    "    {\n",
    "        attribute: {\n",
    "            status: {\n",
    "                count: value,\n",
    "                value: value,\n",
    "            },\n",
    "            ......\n",
    "        },\n",
    "        ......\n",
    "    }\n",
    "    \"\"\"\n",
    "    infoEntropy = {}\n",
    "    for attribute in properties:\n",
    "        infoEntropy[attribute] = calculateInfoEntropy(trainData, propertiesIndex[attribute])\n",
    "    return infoEntropy\n",
    "\n",
    "\n",
    "def calculateNormalizedInfoEntropy(attributeInfoEntropy):\n",
    "    amount = 0\n",
    "    for status in attributeInfoEntropy:\n",
    "        amount = amount + attributeInfoEntropy[status][\"count\"]\n",
    "\n",
    "    normalizedInfoEntropy = 0.0\n",
    "    for status in attributeInfoEntropy:\n",
    "        probability = attributeInfoEntropy[status][\"count\"] / amount\n",
    "        normalizedInfoEntropy = normalizedInfoEntropy + probability * attributeInfoEntropy[status][\"value\"]\n",
    "    return normalizedInfoEntropy\n",
    "\n",
    "\n",
    "def getNormalizedInfoEntropy(infoEntropy):\n",
    "    normalizedInfoEntropy = {}\n",
    "    for attribute in infoEntropy:\n",
    "        normalizedInfoEntropy[attribute] = calculateNormalizedInfoEntropy(infoEntropy[attribute])\n",
    "    return normalizedInfoEntropy\n",
    "\n",
    "\n",
    "def selectNode(trainData, properties, propertiesIndex):\n",
    "    \"\"\"\n",
    "\n",
    "    :param trainData:\n",
    "    :param properties:\n",
    "    :param propertiesIndex:\n",
    "    :return:\n",
    "    node(当前选择的节点属性信息):{\n",
    "        name: 节点属性名称\n",
    "        status: { 各个状态的信息熵\n",
    "            key: {\n",
    "                keys: []\n",
    "                value: value\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    print(\"\\n当前训练集为:\", trainData)\n",
    "    print(\"当前的属性列表为:\", properties)\n",
    "    resultStatistics = {}\n",
    "    for item in trainData:\n",
    "        if trainData[item] not in resultStatistics:\n",
    "            resultStatistics[trainData[item]] = 1\n",
    "        else:\n",
    "            resultStatistics[trainData[item]] = resultStatistics[trainData[item]] + 1\n",
    "\n",
    "    rootInfoEntropy = 0.0\n",
    "    for result in resultStatistics:\n",
    "        probability = resultStatistics[result] / len(trainData)\n",
    "        rootInfoEntropy = rootInfoEntropy + (probability * math.log(probability, 2))\n",
    "    rootInfoEntropy = rootInfoEntropy * -1\n",
    "    print(\"当前训练集的根节点的信息熵:\", rootInfoEntropy)\n",
    "\n",
    "    infoEntropy = getInfoEntropy(trainData, properties, propertiesIndex)\n",
    "    print(\"当前训练集的信息熵:\", infoEntropy)\n",
    "\n",
    "    normalizedInfoEntropy = getNormalizedInfoEntropy(infoEntropy)\n",
    "    print(\"当前训练集的归一化信息熵:\", normalizedInfoEntropy)\n",
    "\n",
    "    infoGain = {}\n",
    "    for attribute in properties:\n",
    "        infoGain[attribute] = rootInfoEntropy - normalizedInfoEntropy[attribute]\n",
    "    print(\"当前训练集的信息增益:\", infoGain)\n",
    "\n",
    "    name = None\n",
    "    for attribute in infoGain:\n",
    "        if name is None:\n",
    "            name = attribute\n",
    "        elif infoGain[attribute] > infoGain[name]:\n",
    "            name = attribute\n",
    "\n",
    "    statusMap = {}\n",
    "    for status in infoEntropy[name]:\n",
    "        statusMap[status] = {}\n",
    "        statusMap[status][\"value\"] = infoEntropy[name][status][\"value\"]\n",
    "        statusMap[status][\"keys\"] = []\n",
    "        for item in trainData:\n",
    "            if item[propertiesIndex[name]] == status:\n",
    "                statusMap[status][\"keys\"].append(item)\n",
    "\n",
    "    node = {\n",
    "        \"name\": name,\n",
    "        \"status\": statusMap,\n",
    "    }\n",
    "    return node\n",
    "\n",
    "\n",
    "def getID3Tree(trainData, properties, propertiesIndex):\n",
    "    \"\"\"\n",
    "    获取ID3决策树\n",
    "    :param trainData:\n",
    "    :param properties:\n",
    "    :param propertiesIndex:\n",
    "    :return:\n",
    "\n",
    "    node(当前选择的节点属性信息):{\n",
    "        name: 节点属性名称\n",
    "        status: { 各个状态的信息熵\n",
    "            key: {\n",
    "                keys: []\n",
    "                value: value\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    node = selectNode(trainData, properties, propertiesIndex)\n",
    "    print(\"当前选择的最优节点为:\", node)\n",
    "    tree = {\n",
    "        node[\"name\"]: {},\n",
    "    }\n",
    "\n",
    "    tempProperties = copy(properties)\n",
    "    print(\"进行属性列表裁剪:\", tempProperties, node[\"name\"])\n",
    "    if node[\"name\"] in tempProperties:\n",
    "        tempProperties.remove(node[\"name\"])\n",
    "\n",
    "    for status in node[\"status\"]:\n",
    "        if node[\"status\"][status][\"value\"] == 0.0:\n",
    "            tree[node[\"name\"]][status] = trainData[node[\"status\"][status][\"keys\"][0]]\n",
    "        else:\n",
    "            tempTrainData = {}\n",
    "            for item in trainData:\n",
    "                if item[propertiesIndex[node[\"name\"]]] == status:\n",
    "                    tempTrainData[item] = trainData[item]\n",
    "\n",
    "            tree[node[\"name\"]][status], nodeName = getID3Tree(tempTrainData, properties, propertiesIndex)\n",
    "            print(\"进行属性列表裁剪:\", tempProperties, nodeName)\n",
    "            if nodeName in properties:\n",
    "                properties.remove(nodeName)\n",
    "\n",
    "    return tree, node[\"name\"]\n",
    "\n",
    "\n",
    "def printTree(tree, interval):\n",
    "    newInterval = interval + \"\\t\"\n",
    "    for item in tree:\n",
    "        if type(tree[item]) is not dict:\n",
    "            print(interval + item, tree[item])\n",
    "        else:\n",
    "            print(interval + item)\n",
    "            printTree(tree[item], newInterval)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    properties = [\"weather\", \"temperature\", \"humidity\", \"windy\"]\n",
    "    propertiesIndex = {\"weather\": 0, \"temperature\": 1, \"humidity\": 2, \"windy\": 3}\n",
    "    # 0:不打篮球 1:打篮球\n",
    "    trainData = {\n",
    "        (\"sun\", \"high\", \"middle\", \"no\"): 0,\n",
    "        (\"sun\", \"high\", \"middle\", \"yes\"): 0,\n",
    "        (\"cloud\", \"high\", \"high\", \"no\"): 1,\n",
    "        (\"rain\", \"high\", \"high\", \"no\"): 1,\n",
    "        (\"rain\", \"low\", \"high\", \"no\"): 0,\n",
    "        (\"sun\", \"middle\", \"middle\", \"yes\"): 1,\n",
    "        (\"cloud\", \"middle\", \"high\", \"yes\"): 0,\n",
    "    }\n",
    "    # for key in trainData:\n",
    "    #     print(key, trainData[key])\n",
    "\n",
    "    tree, name = getID3Tree(trainData, properties, propertiesIndex)\n",
    "    print(str(tree).replace(\"'\", '\"'))\n",
    "    printTree(tree, \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
